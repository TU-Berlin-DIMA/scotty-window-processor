package benchmark.jobs;

import benchmark.LoadGeneratorSource;
import benchmark.ThroughputLogger2;
import benchmark.WatermarkGenerator;
import de.tub.dima.scotty.core.windowType.SlidingWindow;
import de.tub.dima.scotty.core.windowType.TumblingWindow;
import de.tub.dima.scotty.core.windowType.Window;
import de.tub.dima.scotty.stormconnector.ScottyBolt;
import de.tub.dima.scotty.stormconnector.demo.windowFunctions.sumWindowFunction;
import org.apache.storm.Config;
import org.apache.storm.LocalCluster;
import org.apache.storm.topology.TopologyBuilder;
import org.apache.storm.tuple.Fields;
import org.javatuples.Pair;

import java.util.List;

import static java.lang.Math.toIntExact;

public class ScottyBenchmarkJob {
    public ScottyBenchmarkJob(List<Window> assigners, long runtime, int throughput, List<Pair<Long, Long>> gaps) throws InterruptedException {
        LocalCluster cluster = new LocalCluster();
        TopologyBuilder builder = new TopologyBuilder();

        int parallelism_hint = 1;
        Config conf = new Config();
        conf.setDebug(false);
        conf.setNumWorkers(1);
        conf.setMaxTaskParallelism(1);

        //Disable Acking
        conf.setNumAckers(0);

//        conf.put(Config.STORM_ZOOKEEPER_SESSION_TIMEOUT, 100000);
        LoadGeneratorSource generator = new LoadGeneratorSource(runtime, throughput, gaps);
        builder.setSpout("loadGenerator", generator, parallelism_hint);
        builder.setBolt("throughputLogger", new ThroughputLogger2(), parallelism_hint).shuffleGrouping("loadGenerator");
        builder.setBolt("watermarkGenerator", new WatermarkGenerator(), parallelism_hint).shuffleGrouping("loadGenerator");

        ScottyBolt scottyBolt = new ScottyBolt<Integer, Integer>(new sumWindowFunction());
        for (Window w : assigners) {
            int size = 0;
            if (w instanceof SlidingWindow)
                size = toIntExact(((SlidingWindow) w).getSize());
            else if (w instanceof TumblingWindow)
                size = toIntExact(((TumblingWindow) w).getSize());

            conf.setMessageTimeoutSecs(size * 2);
            scottyBolt.addWindow(w);
        }
        builder.setBolt("scottySlidingWindow", scottyBolt, parallelism_hint).fieldsGrouping("watermarkGenerator", new Fields("key"));
        //builder.setBolt("printer", new PrinterBolt(), parallelism_hint).shuffleGrouping("scottySlidingWindow");

        cluster.submitTopology("StormBenchmarkTopology", conf, builder.createTopology());

        //After the topology is submitted, code continues to execute from this line immediately without waiting topology execution
        //We can't kill the topology here because we need to wait enough to have correct throughput mean.

        //killTopology("StormBenchmarkTopology",cluster);

        /* Storm topologies never kill themselves and always waits for the next input tuple!
         *
         * Programmer can kill the topology from a spout/bolt when:
         *  1) Data is no longer generated by the spout
         *  2) Final bolt instance receives a signaling tuple that indicates the end of the stream.
         *
         *  Both cases does not apply to our tests because killing a topology results in not being able to wait enough to reach correct throughput mean.
         *  In order to reach correct mean results we actively wait after the topology submission for an estimate amount of time depending on the workload.
         *
         */

        long endTime = System.currentTimeMillis() + runtime * 2;
        while (System.currentTimeMillis() < endTime) {
            //Actively wait for topology to finish
        }

        //At this moment code returns to the calling "Runner" class and writes the throughput mean to disk.

    }

    public void killTopology(String topoName, LocalCluster cluster) {
        cluster.killTopology(topoName);
        cluster.shutdown();
    }
}
